<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NLP Embeddings Masterclass</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/js/all.min.js"></script>
    <style>
        body { font-family: 'Inter', sans-serif; overflow: hidden; }
        .slide { display: none; height: 100vh; width: 100vw; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.5s ease-in-out; }
        .slide.active { display: flex; opacity: 1; z-index: 10; }
        .slide-content { max-width: 1200px; width: 90%; margin: 0 auto; height: 90%; display: flex; flex-direction: column; justify-content: center; }
        
        /* Animation Classes */
        .fade-up { animation: fadeUp 0.8s ease-out forwards; opacity: 0; transform: translateY(20px); }
        .delay-100 { animation-delay: 0.1s; }
        .delay-200 { animation-delay: 0.3s; }
        .delay-300 { animation-delay: 0.5s; }
        
        @keyframes fadeUp {
            to { opacity: 1; transform: translateY(0); }
        }

        /* vector math animations */
        .vector-path { stroke-dasharray: 1000; stroke-dashoffset: 1000; animation: drawLine 2s forwards; }
        @keyframes drawLine { to { stroke-dashoffset: 0; } }

        /* Speaker Notes Panel */
        #speaker-notes {
            position: fixed; bottom: 0; left: 0; width: 100%; height: 30vh;
            background: #1e293b; color: #e2e8f0; padding: 20px;
            transform: translateY(100%); transition: transform 0.3s ease;
            z-index: 50; border-top: 4px solid #3b82f6; overflow-y: auto;
            font-family: 'Courier New', monospace; font-size: 1.1rem; line-height: 1.6;
        }
        #speaker-notes.open { transform: translateY(0); }
        
        /* Grid Background */
        .grid-bg {
            background-image: radial-gradient(#cbd5e1 1px, transparent 1px);
            background-size: 30px 30px;
        }
        
        .code-block { background: #1e1e1e; color: #d4d4d4; padding: 1rem; border-radius: 0.5rem; font-family: monospace; }
        .highlight { color: #4ec9b0; }
        .highlight-str { color: #ce9178; }
        
        /* Interactive Tooltip */
        .tooltip { position: relative; display: inline-block; border-bottom: 1px dotted black; cursor: help; }
        .tooltip .tooltiptext {
            visibility: hidden; width: 200px; background-color: #555; color: #fff;
            text-align: center; border-radius: 6px; padding: 5px; position: absolute;
            z-index: 1; bottom: 125%; left: 50%; margin-left: -100px; opacity: 0; transition: opacity 0.3s;
        }
        .tooltip:hover .tooltiptext { visibility: visible; opacity: 1; }
    </style>
</head>
<body class="bg-slate-50 text-slate-800">

    <!-- Slide 1: Title -->
    <div class="slide active grid-bg" id="slide-0">
        <div class="slide-content text-center">
            <h1 class="text-6xl font-bold text-blue-700 mb-6 fade-up">Demystifying Embeddings</h1>
            <h2 class="text-3xl text-slate-600 mb-8 fade-up delay-100">From One-Hot to Contextual Vectors</h2>
            <div class="w-full max-w-2xl mx-auto bg-white p-8 rounded-xl shadow-lg fade-up delay-200">
                <p class="text-lg text-slate-500 mb-4">A 1-Hour Deep Dive</p>
                <div class="flex justify-center gap-4 text-sm font-semibold text-slate-400">
                    <span><i class="fas fa-clock"></i> 60 Mins</span>
                    <span><i class="fas fa-layer-group"></i> 20 Slides</span>
                    <span><i class="fas fa-code"></i> Interactive</span>
                </div>
            </div>
            <p class="mt-12 text-slate-400 text-sm fade-up delay-300">Press <kbd class="bg-slate-200 px-2 py-1 rounded">Right Arrow</kbd> to start | Press <kbd class="bg-slate-200 px-2 py-1 rounded">S</kbd> for Speaker Notes</p>
        </div>
    </div>

    <!-- Slide 2: The Problem -->
    <div class="slide bg-white" id="slide-1">
        <div class="slide-content">
            <div class="grid grid-cols-2 gap-12 items-center">
                <div>
                    <h2 class="text-4xl font-bold text-blue-700 mb-6">Recap: The Old Way</h2>
                    <h3 class="text-2xl font-semibold mb-4">One-Hot Encoding</h3>
                    <ul class="list-disc pl-6 space-y-4 text-xl text-slate-600">
                        <li>Vocabulary size = Vector dimension.</li>
                        <li>Vectors are <strong>sparse</strong> (mostly zeros).</li>
                        <li>All vectors are orthogonal (90Â°).</li>
                        <li><strong>Fatal Flaw:</strong> No notion of similarity.</li>
                    </ul>
                </div>
                <div class="bg-slate-100 p-8 rounded-xl shadow-inner font-mono text-sm">
                    <p class="mb-2 text-slate-500">// Vocabulary: [Apple, Banana, Car]</p>
                    <div class="space-y-4">
                        <div class="flex items-center gap-4">
                            <span class="w-20 font-bold">Apple</span>
                            <span class="bg-white px-3 py-1 border rounded">[1, 0, 0]</span>
                        </div>
                        <div class="flex items-center gap-4">
                            <span class="w-20 font-bold">Banana</span>
                            <span class="bg-white px-3 py-1 border rounded">[0, 1, 0]</span>
                        </div>
                        <div class="flex items-center gap-4">
                            <span class="w-20 font-bold">Car</span>
                            <span class="bg-white px-3 py-1 border rounded">[0, 0, 1]</span>
                        </div>
                    </div>
                    <div class="mt-8 pt-8 border-t border-slate-300 text-center">
                        <p class="text-red-500 font-bold">Distance(Apple, Banana) == Distance(Apple, Car)</p>
                        <p class="text-sm text-slate-500 mt-2">Mathematically, they are equally different.</p>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Slide 3: The Intuition -->
    <div class="slide grid-bg" id="slide-2">
        <div class="slide-content">
            <h2 class="text-4xl font-bold text-center text-blue-700 mb-12">The Intuition: Meaning is Context</h2>
            <div class="grid grid-cols-3 gap-8">
                <div class="col-span-1 bg-white p-6 rounded-xl shadow-lg border-l-4 border-blue-500">
                    <h3 class="text-xl font-bold mb-4">Distributional Hypothesis</h3>
                    <p class="text-lg italic text-slate-600">"You shall know a word by the company it keeps."</p>
                    <p class="text-right text-sm text-slate-400 mt-2">- J.R. Firth (1957)</p>
                </div>
                <div class="col-span-2 flex flex-col justify-center items-center bg-white p-6 rounded-xl shadow-lg">
                    <div class="text-2xl mb-6">
                        I drink <span class="font-bold text-blue-600 border-b-2 border-blue-600">coffee</span> every morning.
                    </div>
                    <div class="text-2xl mb-6">
                        I drink <span class="font-bold text-blue-600 border-b-2 border-blue-600">tea</span> every morning.
                    </div>
                    <div class="text-2xl text-slate-400">
                        I drink <span class="font-bold text-red-400 line-through">car</span> every morning.
                    </div>
                    <p class="mt-6 text-slate-600">Because "coffee" and "tea" appear in similar contexts, their vectors should be close in space.</p>
                </div>
            </div>
        </div>
    </div>

    <!-- Slide 4: Dense Vectors -->
    <div class="slide bg-slate-900 text-white" id="slide-3">
        <div class="slide-content">
            <h2 class="text-4xl font-bold text-yellow-400 mb-8">Enter Embeddings: Dense Vectors</h2>
            <div class="flex gap-12 items-center">
                <div class="w-1/2">
                    <p class="text-xl leading-relaxed mb-6">Instead of a 100,000-dimensional sparse vector, we compress meaning into a 50-300 dimensional <strong>dense</strong> vector.</p>
                    <p class="text-xl leading-relaxed">Each dimension represents a latent abstract feature.</p>
                </div>
                <div class="w-1/2 bg-slate-800 p-6 rounded-xl font-mono text-sm relative overflow-hidden">
                    <div class="absolute top-0 right-0 p-2 text-xs text-slate-500">Hypothetical Features</div>
                    <table class="w-full text-center">
                        <thead class="text-slate-400 border-b border-slate-700">
                            <tr><th>Word</th><th>Royalty</th><th>Gender</th><th>Food</th><th>Size</th></tr>
                        </thead>
                        <tbody class="divide-y divide-slate-700">
                            <tr><td class="py-2 text-yellow-300">King</td><td>0.99</td><td>0.99</td><td>0.01</td><td>0.5</td></tr>
                            <tr><td class="py-2 text-yellow-300">Queen</td><td>0.99</td><td>0.01</td><td>0.01</td><td>0.5</td></tr>
                            <tr><td class="py-2 text-green-300">Apple</td><td>0.01</td><td>0.5</td><td>0.95</td><td>0.1</td></tr>
                        </tbody>
                    </table>
                    <div class="mt-4 text-center text-blue-400">
                        <i class="fas fa-arrow-up"></i> In reality, these features are learned and not explicitly named.
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Slide 5: Visualizing Vector Space -->
    <div class="slide bg-white" id="slide-4">
        <div class="slide-content text-center">
            <h2 class="text-4xl font-bold text-blue-700 mb-4">Visualizing Vector Space</h2>
            <p class="text-slate-500 mb-8">Projecting High-Dimensional Meaning into 2D</p>
            
            <div class="relative w-full h-[500px] border-2 border-slate-200 rounded-xl bg-slate-50 overflow-hidden" id="vector-canvas">
                <!-- SVG Vector Visualization -->
                <svg width="100%" height="100%" viewBox="0 0 800 500">
                    <!-- Axes -->
                    <line x1="400" y1="50" x2="400" y2="450" stroke="#cbd5e1" stroke-width="2" />
                    <line x1="50" y1="250" x2="750" y2="250" stroke="#cbd5e1" stroke-width="2" />
                    
                    <!-- Cluster 1: Fruits -->
                    <circle cx="600" cy="150" r="5" fill="green" />
                    <text x="610" y="150" class="text-sm">Apple</text>
                    <circle cx="580" cy="170" r="5" fill="green" />
                    <text x="590" y="170" class="text-sm">Orange</text>
                    <circle cx="620" cy="130" r="5" fill="green" />
                    <text x="630" y="130" class="text-sm">Banana</text>
                    
                    <!-- Cluster 2: Royalty -->
                    <circle cx="200" cy="350" r="5" fill="purple" />
                    <text x="210" y="350" class="text-sm">King</text>
                    <circle cx="230" cy="380" r="5" fill="purple" />
                    <text x="240" y="380" class="text-sm">Queen</text>
                    <circle cx="180" cy="360" r="5" fill="purple" />
                    <text x="190" y="360" class="text-sm">Prince</text>

                    <!-- Cluster 3: Tech -->
                    <circle cx="150" cy="100" r="5" fill="blue" />
                    <text x="160" y="100" class="text-sm">Computer</text>
                    <circle cx="120" cy="120" r="5" fill="blue" />
                    <text x="130" y="120" class="text-sm">Laptop</text>
                    
                    <!-- Connecting lines for similarity -->
                    <line x1="600" y1="150" x2="580" y2="170" stroke="green" stroke-opacity="0.3" stroke-dasharray="4"/>
                    <line x1="200" y1="350" x2="230" y2="380" stroke="purple" stroke-opacity="0.3" stroke-dasharray="4"/>
                </svg>
            </div>
        </div>
    </div>

    <!-- Slide 6: Word2Vec Intro -->
    <div class="slide grid-bg" id="slide-5">
        <div class="slide-content">
            <div class="text-center mb-10">
                <h2 class="text-5xl font-bold text-transparent bg-clip-text bg-gradient-to-r from-blue-600 to-purple-600">Word2Vec</h2>
                <p class="text-xl text-slate-600 mt-2">The 2013 Breakthrough by Mikolov et al. (Google)</p>
            </div>
            <div class="grid grid-cols-2 gap-8">
                <div class="bg-white p-8 rounded-xl shadow-md border-t-4 border-blue-500 hover:scale-105 transition-transform">
                    <h3 class="text-2xl font-bold mb-4 text-blue-700">CBOW</h3>
                    <p class="text-sm uppercase tracking-wide text-slate-400 font-bold">Continuous Bag of Words</p>
                    <p class="mt-4 text-slate-600">Predict the <strong>Target Word</strong> based on its <strong>Context</strong>.</p>
                    <div class="mt-6 bg-slate-100 p-4 rounded text-center font-mono text-sm">
                        [The, quick, ???, fox, jumps] <br>
                        <i class="fas fa-arrow-down my-2 text-slate-400"></i><br>
                        <span class="font-bold text-blue-600">brown</span>
                    </div>
                </div>
                <div class="bg-white p-8 rounded-xl shadow-md border-t-4 border-purple-500 hover:scale-105 transition-transform">
                    <h3 class="text-2xl font-bold mb-4 text-purple-700">Skip-gram</h3>
                    <p class="text-sm uppercase tracking-wide text-slate-400 font-bold">Inverse of CBOW</p>
                    <p class="mt-4 text-slate-600">Predict the <strong>Context Words</strong> based on the <strong>Target</strong>.</p>
                    <div class="mt-6 bg-slate-100 p-4 rounded text-center font-mono text-sm">
                        [???, ???, <span class="font-bold text-purple-600">brown</span>, ???, ???] <br>
                        <i class="fas fa-arrow-down my-2 text-slate-400"></i><br>
                        [The, quick, fox, jumps]
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Slide 7: CBOW Architecture -->
    <div class="slide bg-white" id="slide-6">
        <div class="slide-content text-center">
            <h2 class="text-3xl font-bold text-slate-800 mb-8">Architecture 1: CBOW</h2>
            <svg viewBox="0 0 800 400" class="w-full h-auto">
                <!-- Input Layer -->
                <g transform="translate(100, 50)">
                    <rect x="0" y="0" width="40" height="200" fill="#e2e8f0" stroke="#64748b"/>
                    <text x="20" y="-15" text-anchor="middle" font-size="12">Context (One-Hot)</text>
                </g>
                
                <!-- Hidden Layer -->
                <g transform="translate(350, 100)">
                    <rect x="0" y="0" width="40" height="100" fill="#3b82f6" stroke="#1d4ed8"/>
                    <text x="20" y="-15" text-anchor="middle" font-size="12">Hidden Layer (N)</text>
                    <text x="20" y="130" text-anchor="middle" font-size="10" fill="#64748b">No Activation!</text>
                </g>
                
                <!-- Output Layer -->
                <g transform="translate(600, 50)">
                    <rect x="0" y="0" width="40" height="200" fill="#e2e8f0" stroke="#64748b"/>
                    <text x="20" y="-15" text-anchor="middle" font-size="12">Output (Softmax)</text>
                </g>

                <!-- Connections -->
                <path d="M 140 150 L 350 150" stroke="#94a3b8" stroke-width="2" marker-end="url(#arrow)" />
                <path d="M 390 150 L 600 150" stroke="#94a3b8" stroke-width="2" marker-end="url(#arrow)" />
                
                <!-- Label: Weights -->
                <text x="245" y="140" text-anchor="middle" font-size="12" fill="red">W (N x V)</text>
                <text x="495" y="140" text-anchor="middle" font-size="12" fill="red">W' (V x N)</text>
                
                <!-- Definitions -->
                <defs>
                    <marker id="arrow" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto" markerUnits="strokeWidth">
                        <path d="M0,0 L0,6 L9,3 z" fill="#94a3b8" />
                    </marker>
                </defs>
            </svg>
            <p class="mt-4 text-slate-600 max-w-2xl mx-auto">We average the input context vectors, project them to the hidden dimension, and predict the target word.</p>
        </div>
    </div>

    <!-- Slide 8: Skip-gram Architecture -->
    <div class="slide bg-white" id="slide-7">
        <div class="slide-content text-center">
            <h2 class="text-3xl font-bold text-slate-800 mb-8">Architecture 2: Skip-gram</h2>
            <p class="text-slate-500 mb-6">Better for infrequent words and larger datasets.</p>
             <svg viewBox="0 0 800 400" class="w-full h-auto">
                <!-- Input Layer -->
                <g transform="translate(100, 100)">
                    <rect x="0" y="0" width="40" height="100" fill="#e2e8f0" stroke="#64748b"/>
                    <text x="20" y="-15" text-anchor="middle" font-size="12">Target (One-Hot)</text>
                </g>
                
                <!-- Hidden Layer -->
                <g transform="translate(350, 100)">
                    <rect x="0" y="0" width="40" height="100" fill="#a855f7" stroke="#7e22ce"/>
                    <text x="20" y="-15" text-anchor="middle" font-size="12">Projection</text>
                </g>
                
                <!-- Output Layer -->
                <g transform="translate(600, 50)">
                    <rect x="0" y="0" width="40" height="200" fill="#e2e8f0" stroke="#64748b"/>
                    <text x="20" y="-15" text-anchor="middle" font-size="12">Contexts (Softmax)</text>
                </g>

                <!-- Connections -->
                <path d="M 140 150 L 350 150" stroke="#94a3b8" stroke-width="2" marker-end="url(#arrow)" />
                <path d="M 390 150 L 600 100" stroke="#94a3b8" stroke-width="2" />
                <path d="M 390 150 L 600 150" stroke="#94a3b8" stroke-width="2" />
                <path d="M 390 150 L 600 200" stroke="#94a3b8" stroke-width="2" />
                
                <text x="245" y="140" text-anchor="middle" font-size="12" fill="red">Lookup</text>
            </svg>
            <p class="mt-4 text-slate-600 max-w-2xl mx-auto">Takes one word and tries to maximize the probability of predicting its surrounding words.</p>
        </div>
    </div>

    <!-- Slide 9: The Sliding Window Animation -->
    <div class="slide bg-slate-100" id="slide-8">
        <div class="slide-content text-center">
            <h2 class="text-3xl font-bold mb-12">How Training Data is Created</h2>
            
            <div class="bg-white p-8 rounded-xl shadow-lg inline-block relative overflow-hidden">
                <div class="flex gap-2 text-2xl font-mono" id="sentence-container">
                    <span class="p-2">The</span>
                    <span class="p-2">quick</span>
                    <span class="p-2">brown</span>
                    <span class="p-2">fox</span>
                    <span class="p-2">jumps</span>
                    <span class="p-2">over</span>
                    <span class="p-2">the</span>
                    <span class="p-2">lazy</span>
                    <span class="p-2">dog</span>
                </div>
                <!-- Sliding Window Overlay -->
                <div id="window-highlight" class="absolute top-6 left-0 h-14 border-4 border-blue-500 rounded pointer-events-none transition-all duration-500 bg-blue-100 opacity-30"></div>
            </div>

            <div class="mt-12 grid grid-cols-2 gap-8 max-w-4xl mx-auto">
                <div class="bg-blue-50 p-6 rounded-lg">
                    <h4 class="font-bold text-blue-800">Target (Center)</h4>
                    <p id="target-word" class="text-3xl mt-2 font-mono">quick</p>
                </div>
                <div class="bg-green-50 p-6 rounded-lg">
                    <h4 class="font-bold text-green-800">Context (Neighbors)</h4>
                    <p id="context-words" class="text-3xl mt-2 font-mono">[The, brown]</p>
                </div>
            </div>
            
            <button onclick="animateWindow()" class="mt-8 bg-blue-600 text-white px-6 py-2 rounded hover:bg-blue-700 transition"><i class="fas fa-play"></i> Animate Step</button>
        </div>
    </div>

    <!-- Slide 10: Vector Arithmetic -->
    <div class="slide bg-slate-900 text-white" id="slide-9">
        <div class="slide-content text-center">
            <h2 class="text-4xl font-bold mb-12">The "Magic" of Linear Substructures</h2>
            
            <div class="flex justify-center items-center gap-8 text-3xl font-mono mb-12">
                <div class="text-center">
                    <div class="text-purple-400">King</div>
                    <div class="text-sm text-slate-500">[0.9, 0.8]</div>
                </div>
                <div class="text-slate-400">-</div>
                <div class="text-center">
                    <div class="text-blue-400">Man</div>
                    <div class="text-sm text-slate-500">[0.1, 0.8]</div>
                </div>
                <div class="text-slate-400">+</div>
                <div class="text-center">
                    <div class="text-pink-400">Woman</div>
                    <div class="text-sm text-slate-500">[0.1, 0.2]</div>
                </div>
                <div class="text-slate-400">=</div>
                <div class="text-center relative">
                    <div class="text-yellow-400 font-bold animate-pulse">Queen</div>
                    <div class="text-sm text-slate-500">[0.9, 0.2]</div>
                    <div class="absolute -top-8 left-0 w-full text-xs text-green-400">Result Vector</div>
                </div>
            </div>

            <div class="max-w-3xl mx-auto text-lg text-slate-300 bg-slate-800 p-6 rounded-xl">
                This property wasn't explicitly programmed! It emerged from the training data. The model learned that the direction from <em>Man</em> to <em>King</em> is the same "Royalty" vector as <em>Woman</em> to <em>Queen</em>.
            </div>
        </div>
    </div>

    <!-- Slide 11: GloVe -->
    <div class="slide grid-bg" id="slide-10">
        <div class="slide-content">
            <h2 class="text-4xl font-bold text-slate-800 mb-6">GloVe: Global Vectors</h2>
            <div class="flex gap-12">
                <div class="w-1/2">
                    <h3 class="text-xl font-bold text-blue-600 mb-4">The Hybrid Approach</h3>
                    <ul class="list-disc pl-6 space-y-4 text-lg">
                        <li><strong>Word2Vec</strong> relies on local context windows.</li>
                        <li><strong>GloVe</strong> (Pennington et al., 2014) leverages global word-word co-occurrence statistics.</li>
                        <li>It builds a huge matrix of probabilities: <br> <code class="bg-slate-200 px-2 rounded">P(solid | ice)</code> vs <code class="bg-slate-200 px-2 rounded">P(gas | ice)</code>.</li>
                        <li>Faster to train on smaller corpora, very stable embeddings.</li>
                    </ul>
                </div>
                <div class="w-1/2 bg-white p-6 rounded-xl shadow-lg">
                     <h4 class="font-bold text-center mb-4">Co-occurrence Matrix Example</h4>
                     <table class="w-full text-sm border-collapse border border-slate-300">
                         <tr class="bg-slate-100"><th></th><th>Ice</th><th>Steam</th><th>Fashion</th></tr>
                         <tr><td class="font-bold">Solid</td><td class="bg-blue-100">High</td><td class="bg-red-50">Low</td><td class="bg-red-50">Low</td></tr>
                         <tr><td class="font-bold">Gas</td><td class="bg-red-50">Low</td><td class="bg-blue-100">High</td><td class="bg-red-50">Low</td></tr>
                         <tr><td class="font-bold">Water</td><td class="bg-blue-200">Med</td><td class="bg-blue-200">Med</td><td class="bg-red-50">Low</td></tr>
                     </table>
                     <p class="mt-4 text-sm text-slate-500 italic">GloVe factorizes this matrix to find vector representations.</p>
                </div>
            </div>
        </div>
    </div>

    <!-- Slide 12: Problem with Static Embeddings -->
    <div class="slide bg-red-50" id="slide-11">
        <div class="slide-content text-center">
            <h2 class="text-4xl font-bold text-red-700 mb-8"><i class="fas fa-exclamation-triangle"></i> The Limit of Static Embeddings</h2>
            
            <div class="text-3xl font-mono mb-8 space-y-4">
                <div class="bg-white p-4 rounded shadow">
                    I went to the <span class="text-blue-600 font-bold border-2 border-blue-600 p-1 rounded">bank</span> to deposit money.
                </div>
                <div class="bg-white p-4 rounded shadow">
                    I sat on the river <span class="text-green-600 font-bold border-2 border-green-600 p-1 rounded">bank</span>.
                </div>
            </div>

            <div class="bg-white p-8 rounded-xl shadow-lg max-w-2xl mx-auto">
                <p class="text-xl mb-4">In Word2Vec/GloVe:</p>
                <div class="text-2xl font-mono text-slate-700 mb-4">
                    Vector(<span class="text-blue-600">bank</span>) == Vector(<span class="text-green-600">bank</span>)
                </div>
                <p class="text-slate-500">The model collapses all meanings of polysemous words into one average vector.</p>
            </div>
        </div>
    </div>

    <!-- Slide 13: ELMo & BERT -->
    <div class="slide bg-slate-900 text-white" id="slide-12">
        <div class="slide-content">
            <h2 class="text-4xl font-bold text-purple-400 mb-8">The Revolution: Contextual Embeddings</h2>
            
            <div class="grid grid-cols-2 gap-12">
                <div>
                    <h3 class="text-2xl font-bold mb-4">ELMo (2018) & BERT (2019)</h3>
                    <p class="text-lg leading-relaxed mb-6">Instead of a static dictionary look-up, we use a deep neural network to generate the vector <strong>on the fly</strong> based on the entire sentence.</p>
                    <div class="bg-slate-800 p-4 rounded border-l-4 border-green-400">
                        <p class="font-mono text-sm">f(word, context) -> vector</p>
                    </div>
                </div>
                <div class="relative">
                    <svg viewBox="0 0 400 300" class="w-full">
                        <rect x="50" y="200" width="300" height="40" fill="#334155" rx="5" />
                        <text x="200" y="225" text-anchor="middle" fill="white" font-size="14">Input Sentence</text>
                        
                        <!-- Transformer Block -->
                        <rect x="50" y="100" width="300" height="80" fill="#7c3aed" rx="5" opacity="0.8" />
                        <text x="200" y="145" text-anchor="middle" fill="white" font-size="16" font-weight="bold">BERT / Transformer</text>
                        
                        <!-- Outputs -->
                        <circle cx="100" cy="50" r="10" fill="#4ade80" />
                        <circle cx="150" cy="50" r="10" fill="#4ade80" />
                        <circle cx="200" cy="50" r="10" fill="#4ade80" />
                        <circle cx="300" cy="50" r="10" fill="#4ade80" />
                        
                        <!-- Arrows -->
                        <path d="M 200 200 L 200 180" stroke="white" stroke-width="2" />
                        <path d="M 200 100 L 200 80" stroke="white" stroke-width="2" />
                        
                        <text x="350" y="55" fill="#4ade80" font-size="12">Dynamic Vectors</text>
                    </svg>
                </div>
            </div>
        </div>
    </div>

    <!-- Slide 14: Applications -->
    <div class="slide grid-bg" id="slide-13">
        <div class="slide-content">
            <h2 class="text-4xl font-bold text-blue-700 mb-8">What can we do with them?</h2>
            
            <div class="grid grid-cols-3 gap-6">
                <!-- App 1 -->
                <div class="bg-white p-6 rounded-xl shadow hover:shadow-xl transition">
                    <div class="text-4xl text-blue-500 mb-4"><i class="fas fa-search"></i></div>
                    <h3 class="text-xl font-bold mb-2">Semantic Search</h3>
                    <p class="text-slate-600 text-sm">Search for "Smartphone" and get results for "iPhone" and "Android" because their vectors are close.</p>
                </div>
                 <!-- App 2 -->
                <div class="bg-white p-6 rounded-xl shadow hover:shadow-xl transition">
                    <div class="text-4xl text-green-500 mb-4"><i class="fas fa-language"></i></div>
                    <h3 class="text-xl font-bold mb-2">Machine Translation</h3>
                    <p class="text-slate-600 text-sm">Aligning vector spaces of different languages allowed for early neural translation improvements.</p>
                </div>
                 <!-- App 3 -->
                <div class="bg-white p-6 rounded-xl shadow hover:shadow-xl transition">
                    <div class="text-4xl text-purple-500 mb-4"><i class="fas fa-robot"></i></div>
                    <h3 class="text-xl font-bold mb-2">LLMs (GPT/Claude)</h3>
                    <p class="text-slate-600 text-sm">Embeddings are the fundamental input layer for all Large Language Models.</p>
                </div>
            </div>
        </div>
    </div>
    
    <!-- Slide 15: Dimensionality Reduction -->
     <div class="slide bg-white" id="slide-14">
        <div class="slide-content">
            <h2 class="text-4xl font-bold text-slate-800 mb-6">Handling 768 Dimensions</h2>
            <p class="text-xl text-slate-600 mb-8">We can't visualize 768 dimensions. We need 2D or 3D.</p>
            
            <div class="grid grid-cols-2 gap-12">
                <div>
                     <h3 class="font-bold text-blue-600 text-2xl mb-4">PCA (Principal Component Analysis)</h3>
                     <p class="mb-4">Linear reduction. Rotates the axes to maximize variance. Good for global structure.</p>
                     
                     <h3 class="font-bold text-purple-600 text-2xl mb-4">t-SNE & UMAP</h3>
                     <p>Non-linear. Preserves local neighborhoods. Great for visualizing clusters (like the King/Queen examples).</p>
                </div>
                <div class="flex items-center justify-center">
                     <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/Mnist_tsne_2_500.png/440px-Mnist_tsne_2_500.png" alt="t-SNE visualization example" class="rounded-lg shadow-lg opacity-80" />
                     <p class="text-xs text-center mt-2 text-slate-400">Example: t-SNE on MNIST</p>
                </div>
            </div>
        </div>
    </div>

    <!-- Slide 16: Summary -->
    <div class="slide bg-slate-900 text-white" id="slide-15">
        <div class="slide-content text-center">
            <h2 class="text-5xl font-bold text-transparent bg-clip-text bg-gradient-to-r from-blue-400 to-green-400 mb-12">Summary & Takeaways</h2>
            
            <div class="grid grid-cols-2 gap-8 text-left max-w-4xl mx-auto">
                <div class="p-4 border-l-4 border-red-500">
                    <h4 class="font-bold text-xl mb-2">One-Hot</h4>
                    <p class="text-slate-400">Sparse, high-dimensional, no semantic meaning.</p>
                </div>
                <div class="p-4 border-l-4 border-blue-500">
                    <h4 class="font-bold text-xl mb-2">Word2Vec / GloVe</h4>
                    <p class="text-slate-400">Dense, semantic algebra, but static (one vector per word).</p>
                </div>
                 <div class="p-4 border-l-4 border-purple-500">
                    <h4 class="font-bold text-xl mb-2">BERT / Transformers</h4>
                    <p class="text-slate-400">Contextual, dynamic vectors. State of the art.</p>
                </div>
                <div class="p-4 border-l-4 border-yellow-500">
                    <h4 class="font-bold text-xl mb-2">The Future</h4>
                    <p class="text-slate-400">Multimodal embeddings (Image + Text) in same vector space.</p>
                </div>
            </div>
        </div>
    </div>

    <!-- Controls -->
    <div class="fixed bottom-8 right-8 flex gap-4 z-50">
        <button onclick="prevSlide()" class="bg-white/90 p-4 rounded-full shadow-lg hover:bg-blue-50 transition text-blue-600"><i class="fas fa-arrow-left"></i></button>
        <button onclick="nextSlide()" class="bg-white/90 p-4 rounded-full shadow-lg hover:bg-blue-50 transition text-blue-600"><i class="fas fa-arrow-right"></i></button>
    </div>
    
    <!-- Speaker Notes Toggle -->
    <button onclick="toggleSpeakerNotes()" class="fixed bottom-8 left-8 bg-slate-800 text-white px-4 py-2 rounded shadow opacity-50 hover:opacity-100 transition z-50 text-sm">
        Speaker Mode (S)
    </button>

    <!-- Speaker Notes Container -->
    <div id="speaker-notes">
        <h3 class="text-blue-400 font-bold mb-2">Speaker Notes:</h3>
        <div id="note-content"></div>
    </div>

    <script>
        let currentSlide = 0;
        const totalSlides = 16;
        
        // Detailed Speaker Notes for 1-Hour Lecture
        const speakerNotes = [
            "SLIDE 1: INTRO\n\nWelcome everyone. Today we are spending the next hour demystifying one of the most critical concepts in modern NLP: Embeddings.\n\nTiming: 5 mins.\nKey Points:\n- Establish the goal: How do machines 'understand' words?\n- Overview of the journey: From simple counting to deep learning.\n- Mention that this is the foundation for ChatGPT and LLMs.",
            
            "SLIDE 2: RECAP ONE-HOT\n\nLet's start with what you already know. One-Hot Encoding.\n\nTiming: 5 mins.\nAsk class: 'If I have a vocabulary of 50,000 words, how big is my vector?'\nAnswer: 50,000 size.\n\nHighlight the problem of Orthogonality: In this space, 'Hotel' and 'Motel' are just as different as 'Hotel' and 'Tuna'. The dot product is zero. There is no information sharing.",
            
            "SLIDE 3: INTUITION\n\nTiming: 5 mins.\nIntroduce the 'Distributional Hypothesis'. This is a linguistic concept, not a math one initially. \n\n'You shall know a word by the company it keeps.'\n\nWalk through the example: If 'Coffee' and 'Tea' both appear near 'Drink', 'Morning', 'Cup'... the model should suspect they are related.",
            
            "SLIDE 4: DENSE VECTORS\n\nTiming: 5 mins.\nContrast Sparse vs Dense.\n- Sparse: 0s everywhere, one 1.\n- Dense: Float values everywhere.\n\nExplain the table: These numbers are 'features'. In the example, we labeled them (Royalty, Gender), but in reality, the neural network invents its own abstract features that we often can't interpret.",
            
            "SLIDE 5: VISUALIZATION\n\nTiming: 5 mins.\nThis is a 2D projection of a High-D space.\n\nPoint out the clusters.\n- Fruits are together.\n- Royalty is together.\n- Tech is together.\n\nThe distance represents semantic similarity. Euclidean distance or Cosine Similarity is used here.",
            
            "SLIDE 6: WORD2VEC INTRO\n\nTiming: 5 mins.\nThe big breakthrough: Word2Vec (2013). \n\nExplain the two flavors:\n1. CBOW: Fill in the blank. Good for general context.\n2. Skip-gram: Given the word, guess the context. Often performs better on semantic tasks and rare words.",
            
            "SLIDE 7: CBOW ARCHITECTURE\n\nTiming: 5 mins.\nWalk through the Neural Net layers.\n- Input: Context words (averaged).\n- Hidden Layer: This IS the embedding! The weight matrix W acts as a lookup table.\n- Output: Probability of target word.\n\nCrucial point: We don't care about the output prediction as much as we care about the weights learned in the Hidden Layer.",
            
            "SLIDE 8: SKIP-GRAM ARCHITECTURE\n\nTiming: 5 mins.\nInverse of CBOW.\nNotice the input is just one word.\nComputationally expensive because we calculate loss for multiple context words.\nOptimizations used: Negative Sampling (not shown, but mention it). We don't update all weights, just the correct word and a few random wrong words.",
            
            "SLIDE 9: SLIDING WINDOW\n\nTiming: 5 mins.\nInteractive Demo.\n\nClick 'Animate Step' to show how the dataset is built. \nExplain that one sentence produces MULTIPLE training examples. \n(The, brown) -> quick\n(quick, fox) -> brown\nThis massive data augmentation is why Word2Vec works so well on Wikipedia dumps.",
            
            "SLIDE 10: VECTOR MATH\n\nTiming: 5 mins.\nThe most famous slide in NLP.\nKing - Man + Woman = Queen.\n\nExplain what this means geometrically: The vector representing the concept of 'Gender' is constant. If you take King and subtract the 'Male' component and add 'Female', you land on Queen.",
            
            "SLIDE 11: GLOVE\n\nTiming: 5 mins.\nWord2Vec is predictive. GloVe is count-based.\nGloVe creates a giant matrix of how often words appear together globally, then factorizes it.\n\nWhy use GloVe? Often faster to train, deterministic (same result every run), and captures global statistics better than local windows.",
            
            "SLIDE 12: LIMITATIONS\n\nTiming: 3 mins.\nThe Polysemy Problem.\n\nAsk: 'What happens to the vector for Apple?'\nIt's an average of the fruit and the tech company.\nThis results in a 'muddy' vector that is neither perfectly fruit nor perfectly tech.",
            
            "SLIDE 13: CONTEXTUAL EMBEDDINGS\n\nTiming: 5 mins.\nSolution: ELMo and BERT.\n\nKey Concept: Static vs Dynamic.\nWord2Vec: Dictionary lookup (One word = One vector).\nBERT: Function lookup (One word + Context = Unique Vector).\n\nShow the diagram: The vector for 'Apple' changes depending on the words around it.",
            
            "SLIDE 14: APPLICATIONS\n\nTiming: 2 mins.\nBriefly touch on Semantic Search (Google Search uses this now) and Translation.",
            
            "SLIDE 15: DIM REDUCTION\n\nTiming: 2 mins.\nHow do we see 768 dimensions? \nt-SNE and PCA. \nWarning: t-SNE can sometimes create clusters that aren't real, be careful with interpretation.",
            
            "SLIDE 16: CONCLUSION\n\nTiming: 3 mins.\nRecap the journey.\nQ&A Session."
        ];

        function showSlide(n) {
            // Hide current
            const current = document.getElementById(`slide-${currentSlide}`);
            current.classList.remove('active');
            
            // Update index
            currentSlide = (n + totalSlides) % totalSlides;
            
            // Show new
            const next = document.getElementById(`slide-${currentSlide}`);
            next.classList.add('active');
            
            // Update Speaker Notes
            document.getElementById('note-content').innerText = speakerNotes[currentSlide] || "No notes for this slide.";
        }

        function nextSlide() { showSlide(currentSlide + 1); }
        function prevSlide() { showSlide(currentSlide - 1); }
        function toggleSpeakerNotes() { document.getElementById('speaker-notes').classList.toggle('open'); }

        // Keyboard Nav
        document.addEventListener('keydown', (e) => {
            if(e.key === 'ArrowRight') nextSlide();
            if(e.key === 'ArrowLeft') prevSlide();
            if(e.key === 's' || e.key === 'S') toggleSpeakerNotes();
        });

        // Sliding Window Logic for Slide 9
        const words = ["The", "quick", "brown", "fox", "jumps", "over", "the", "lazy", "dog"];
        let windowIndex = 1; // Center word index
        
        function animateWindow() {
            if(windowIndex >= words.length - 1) windowIndex = 1;
            
            const center = words[windowIndex];
            const context = [words[windowIndex-1], words[windowIndex+1]];
            
            document.getElementById('target-word').innerText = center;
            document.getElementById('context-words').innerText = `[${context.join(", ")}]`;
            
            // Move Highlight Visual
            const highlight = document.getElementById('window-highlight');
            // Rough calculation for visualization (assuming uniform width for simplicity in demo)
            // In a real app, we'd calculate offsetLeft
            highlight.style.transform = `translateX(${(windowIndex - 1) * 60}px)`; // Approx movement
            
            windowIndex++;
        }

        // Initialize
        showSlide(0);
    </script>
</body>
</html>